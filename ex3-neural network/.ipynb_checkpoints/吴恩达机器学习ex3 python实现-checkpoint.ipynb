{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0016636F54174DC59922A759D2A637E6",
    "mdEditEnable": false
   },
   "source": [
    "这个项目包含了吴恩达机器学习ex3的python实现，主要知识点为多类别逻辑回归、神经网络，题目内容可以查看数据集中的ex3.pdf\n",
    "代码来自网络（原作者[黄广海的github](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes)），添加了部分对于题意的中文翻译，以及修改成与习题一致的结构，方便大家理解\n",
    "\n",
    "另，补充了开头的可视化部分以及2的使用前馈神经网络预测手写数字\n",
    "我发现matrix和array类型的乘法非常的tricky，所以建议大家写的时候统一用一种！\n",
    "\n",
    "其余练习的传送门\n",
    "[ex1：线性回归](https://www.kesci.com/home/project/5da16a37037db3002d441810)\n",
    "[ex2：逻辑回归、正则化](https://www.kesci.com/home/project/5da1829c037db3002d445baa)\n",
    "[ex3：多类别逻辑回归、神经网络](https://www.kesci.com/home/project/5da56d46c83fb4004202c42b)\n",
    "[ex4：反向传播神经网络](https://www.kesci.com/home/project/5da6bd34c83fb40042068a41)\n",
    "[ex5：偏差和方差、训练集&验证集&测试集](https://www.kesci.com/home/project/5da95c65c83fb400420f2b61)\n",
    "[ex6：支持向量机](https://www.kesci.com/home/project/5da961c8c83fb400420f3dd7)\n",
    "[ex7：K-means和PCA（主要成分分析）](https://www.kesci.com/home/project/5dad17f95f73ad002da303db)\n",
    "[ex8：异常检测和推荐系统（协同过滤）](https://www.kesci.com/home/project/5dad1aa85f73ad002da30562)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B0AABB26658425C8FAEEA76457F53D0",
    "mdEditEnable": false
   },
   "source": [
    "# 1 多分类\n",
    "这个部分需要你实现手写数字（0到9）的识别。你需要扩展之前的逻辑回归，并将其应用于一对多的分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "76734A8429174A4E8BDC583362D3C56A",
    "mdEditEnable": false
   },
   "source": [
    "## 数据集\n",
    "这是一个MATLAB格式的.m文件，其中包含5000个20*20像素的手写字体图像，以及他对应的数字。另外，数字0的y值，对应的是10\n",
    "用Python读取我们需要使用SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "470A673471BD46688BE1E6D19CFBA9DA",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import classification_report#这个包是评价报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "90ED0289DC184364B1612F1158AE3071",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('/home/kesci/input/andrew_ml_ex33507/ex3data1.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F37F4147CBA34C58854D01B4B2714757",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape, data['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80A0C4BF35764989894A2F9925883E42",
    "mdEditEnable": false
   },
   "source": [
    "## 1.2 数据可视化\n",
    "随机展示100个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "539AD3ECA7AD4EE5B0FDD5DD2E13DA7B",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = np.random.choice(np.arange(data['X'].shape[0]), 100)\n",
    "sample_images = data['X'][sample_idx, :]\n",
    "sample_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DF4E1CF70CAE4051BA014F7F6727CD38",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/rt_upload/DF4E1CF70CAE4051BA014F7F6727CD38/pzgfu4m2gy.png\">"
      ],
      "text/plain": [
       "<Figure size 864x864 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax_array = plt.subplots(nrows=10, ncols=10, sharey=True, sharex=True, figsize=(12, 12))\n",
    "for r in range(10):\n",
    "    for c in range(10):\n",
    "        ax_array[r, c].matshow(np.array(sample_images[10 * r + c].reshape((20, 20))).T,cmap=matplotlib.cm.binary)\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6055DB67C8F747B2ABAD49DCC89DE0EC",
    "mdEditEnable": false
   },
   "source": [
    "## 1.3 将逻辑回归向量化\n",
    "你将用多分类逻辑回归做一个分类器。因为现在有10个数字类别，所以你需要训练10个不同的逻辑回归分类器。为了让训练效率更高，将逻辑回归向量化是非常重要的，不要用循环。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EEC2B80A6784C25AE791666BAB45D14",
    "mdEditEnable": false
   },
   "source": [
    "### 1.3.1 向量化代价函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B08CFF660AFA496499E45235DE725061",
    "mdEditEnable": false
   },
   "source": [
    "# sigmoid 函数\n",
    "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为：\n",
    "$$\n",
    "g( z )=\\frac{1}{1+{{e}^{-z}}}\n",
    "$$\n",
    "合起来，我们得到逻辑回归模型的假设函数：\n",
    "$$\n",
    "{{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta }^{T}}X}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B77DA297D8604E1A8E94AA6CFF9F886C",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9EFCEC88D8E4F4D88C91726E7C59EA8",
    "mdEditEnable": false
   },
   "source": [
    "代价函数：\n",
    "$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "B867B454C78648CA964F63140621B4C4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    reg = (learningRate / (2 * len(X))) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
    "    return np.sum(first - second) / len(X) + reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57797287459944D98194FCB083BC7E99",
    "mdEditEnable": false
   },
   "source": [
    "### 1.3.2 向量化梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BB55E4DA49F41B687E2153FD2D9C753",
    "mdEditEnable": false
   },
   "source": [
    "没正则化的时候，逻辑回归的代价是一个向量，第j个元素定义如下：\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial {\\theta }_{j}}=\\frac{1}{m}\\sum\\limits_{i=1}^{m}\\left({({{h}_{\\theta }}( {{x}^{(i)}})-{{y}^{(i)}})x_j^{(i)}} \\right)\n",
    "$$\n",
    "想要正则化它，我们先把他每一行都写出来\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/pzg55zireb.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "$$\n",
    "=\\frac{1}{m}\\sum\\limits_{i=1}^{m}\\left({({{h}_{\\theta }}( {{x}^{(i)}})-{{y}^{(i)}})x^{(i)}} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\frac{1}{m}X^T(h_\\theta(x)-y)\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/pzg5hv15kl.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "记住，$x^{(i)}$是一个向量，但$(h_\\theta(x^{(i)})-y^{(i)})$是一个数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F1A21089B594A9281B31E8000ABDC81",
    "mdEditEnable": false
   },
   "source": [
    "要理解前面式子的最后一步，我们令$\\beta_i=(h_\\theta(x^{(i)})-y^{(i)})$。于是我们可以得出如下等式\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/pzg620rrxj.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "$\\sum\\limits_i\\beta_ix^{(i)}$是$n*1$的向量，与一开始等式左边$\\frac{\\partial J}{\\partial {\\theta }_{n}}$的$n*1$向量对应，$X^T$后为$n*m$，$\\beta_m$的列向量是$m*1$,二者相乘之后是$n*1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBF0FA944A0A4291BC46D733F8E4C937",
    "mdEditEnable": false
   },
   "source": [
    "### 1.3.3 向量化正则化逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDAFFF8DDF9149BB949229B84D6B9708",
    "mdEditEnable": false
   },
   "source": [
    "梯度更新公式如下：\n",
    "$$\n",
    "{{\\theta }_{0}}:={{\\theta }_{0}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{({{h}_{\\theta }}( {{x}^{(i)}} )-{{y}^{(i)}})x_{_{0}}^{(i)}} \n",
    "$$\n",
    "$$\n",
    "{{\\theta }_{j}}:={{\\theta }_{j}}-a(\\frac{1}{m}\\sum\\limits_{i=1}^{m}{({{h}_{\\theta }}( {{x}^{(i)}} )-{{y}^{(i)}})x_{j}^{(i)}}+\\frac{\\lambda }{m}{{\\theta }_{j}})\n",
    "$$\n",
    "向量化后的梯度更新公式如下：\n",
    "$$\n",
    "{{\\theta }_{0}}:={{\\theta }_{0}}-a\\frac{1}{m}(h_\\theta(x)-y)\\cdot x_{_{0}}\n",
    "$$\n",
    "$$\n",
    "{{\\theta }_{j}}:={{\\theta }_{j}}-a(\\frac{1}{m}X^T(h_\\theta(x)-y)+\\frac{\\lambda }{m}{{\\theta }_{j}})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "020B22C6698D4CE785C0A73244DBB447",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    grad = ((X.T * error) / len(X)).T + ((learningRate / len(X)) * theta)\n",
    "    \n",
    "    # intercept gradient is not regularized\n",
    "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / len(X)\n",
    "    \n",
    "    return np.array(grad).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FD9BEE314904B1883FD915E7D2F93E6",
    "mdEditEnable": false
   },
   "source": [
    "## 1.4 一对多分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10FF12340C1F44A38C23F4ABD635107B",
    "mdEditEnable": false
   },
   "source": [
    "现在我们已经定义了代价函数和梯度函数，现在是构建分类器的时候了。\n",
    "对于这个任务，我们有10个可能的类，并且由于逻辑回归只能一次在2个类之间进行分类，我们需要多类分类的策略。\n",
    "在本练习中，我们的任务是实现一对一全分类方法，其中具有k个不同类的标签就有k个分类器，每个分类器在“类别 i”和“不是 i”之间决定。\n",
    "我们将把分类器训练包含在一个函数中，该函数计算10个分类器中的每个分类器的最终权重，并将权重返回为k*(n + 1)数组，其中n是参数数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BC5A83ADCF044DE8803EFD46C20719C9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def one_vs_all(X, y, num_labels, learning_rate):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    \n",
    "    # k * (n + 1) array for the parameters of each of the k classifiers\n",
    "    all_theta = np.zeros((num_labels, params + 1))\n",
    "    \n",
    "    # insert a column of ones at the beginning for the intercept term\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "    \n",
    "    # labels are 1-indexed instead of 0-indexed\n",
    "    for i in range(1, num_labels + 1):\n",
    "        theta = np.zeros(params + 1)\n",
    "        y_i = np.array([1 if label == i else 0 for label in y])\n",
    "        y_i = np.reshape(y_i, (rows, 1))\n",
    "        \n",
    "        # minimize the objective function\n",
    "        fmin = minimize(fun=cost, x0=theta, args=(X, y_i, learning_rate), method='TNC', jac=gradient)\n",
    "        all_theta[i-1,:] = fmin.x\n",
    "    \n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "842FB931D3D6438080B7FD054665FC71",
    "mdEditEnable": false
   },
   "source": [
    "这里需要注意的几点：首先，我们为theta添加了一个额外的参数（与训练数据一列），以计算截距项（常数项）。 其次，我们将y从类标签转换为每个分类器的二进制值（要么是类i，要么不是类i）。 最后，我们使用SciPy的较新优化API来最小化每个分类器的代价函数。 如果指定的话，API将采用目标函数，初始参数集，优化方法和jacobian（渐变）函数。 然后将优化程序找到的参数分配给参数数组。\n",
    "\n",
    "实现向量化代码的一个更具挑战性的部分是正确地写入所有的矩阵，保证维度正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DF58761D802C49DD8EA8424C18CB2A59",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 1), (401,), (10, 401))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = data['X'].shape[0]\n",
    "params = data['X'].shape[1]\n",
    "\n",
    "all_theta = np.zeros((10, params + 1))\n",
    "\n",
    "X = np.insert(data['X'], 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "theta = np.zeros(params + 1)\n",
    "\n",
    "y_0 = np.array([1 if label == 0 else 0 for label in data['y']])\n",
    "y_0 = np.reshape(y_0, (rows, 1))\n",
    "\n",
    "X.shape, y_0.shape, theta.shape, all_theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFDEFF9F59D2475781BE41A734BD9A8C",
    "mdEditEnable": false
   },
   "source": [
    "注意，theta是一维数组，因此当它被转换为计算梯度的代码中的矩阵时，它变为（1×401）矩阵。 我们还检查y中的类标签，以确保它们看起来像我们想象的一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "126433824EB941D0B478405AE9960F47",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['y'])#看下有几类标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C80A917317004B978BD9A6F1A84392C5",
    "mdEditEnable": false
   },
   "source": [
    "让我们确保我们的训练函数正确运行，并且得到合理的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BDF222D219534B7288BCAB313EC50428",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.38382933e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.30435266e-03, -7.38139538e-10,  0.00000000e+00],\n",
       "       [-3.18535755e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         4.45897255e-03, -5.08368421e-04,  0.00000000e+00],\n",
       "       [-4.79761492e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -2.86815478e-05, -2.47202157e-07,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-7.99021031e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -8.93563632e-05,  7.20138723e-06,  0.00000000e+00],\n",
       "       [-4.57308777e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -1.33414489e-03,  9.97008237e-05,  0.00000000e+00],\n",
       "       [-5.40449060e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -1.16595185e-04,  7.88110275e-06,  0.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_theta = one_vs_all(data['X'], data['y'], 10, 1)\n",
    "all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AE098DFD23C46B081978AFCCD9FE900",
    "mdEditEnable": false
   },
   "source": [
    "### 1.4.1 一对多预测\n",
    "\n",
    "我们现在准备好最后一步 - 使用训练完毕的分类器预测每个图像的标签。 对于这一步，我们将计算每个类的类概率，对于每个训练样本（使用当然的向量化代码），并将输出类标签为具有最高概率的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "80CB5D69F9C442818E08B2D24A2676FE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict_all(X, all_theta):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    num_labels = all_theta.shape[0]\n",
    "    \n",
    "    # same as before, insert ones to match the shape\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "    \n",
    "    # convert to matrices\n",
    "    X = np.matrix(X)\n",
    "    all_theta = np.matrix(all_theta)\n",
    "    \n",
    "    # compute the class probability for each class on each training instance\n",
    "    h = sigmoid(X * all_theta.T)\n",
    "    \n",
    "    # create array of the index with the maximum probability\n",
    "    h_argmax = np.argmax(h, axis=1)\n",
    "    \n",
    "    # because our array was zero-indexed we need to add one for the true label prediction\n",
    "    h_argmax = h_argmax + 1\n",
    "    \n",
    "    return h_argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93978D066F7E489DB3220EBD57436B00",
    "mdEditEnable": false
   },
   "source": [
    "现在我们可以使用predict_all函数为每个实例生成类预测，看看我们的分类器是如何工作的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A0376593DC044562A1BE21F5A67A239F",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.99      0.97       500\n",
      "           2       0.95      0.92      0.93       500\n",
      "           3       0.95      0.91      0.93       500\n",
      "           4       0.95      0.95      0.95       500\n",
      "           5       0.92      0.92      0.92       500\n",
      "           6       0.97      0.98      0.97       500\n",
      "           7       0.95      0.95      0.95       500\n",
      "           8       0.93      0.92      0.92       500\n",
      "           9       0.92      0.92      0.92       500\n",
      "          10       0.97      0.99      0.98       500\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5000\n",
      "   macro avg       0.94      0.94      0.94      5000\n",
      "weighted avg       0.94      0.94      0.94      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_all(data['X'], all_theta)\n",
    "print(classification_report(data['y'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA84BD1239D14A16882AB42C73F0BFFC",
    "mdEditEnable": false
   },
   "source": [
    "# 2 神经网络\n",
    "在前面一个部分，我们已经实现了多分类逻辑回归来识别手写数字。但是，逻辑回归并不能承载更复杂的假设，因为他就是个线性分类器。\n",
    "这部分，你需要实现一个可以识别手写数字的神经网络。神经网络可以表示一些非线性复杂的模型。权重已经预先训练好，你的目标是在现有权重基础上，实现前馈神经网络。\n",
    "## 2.1 模型表达\n",
    "现有模型图示如下\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/pzgbmb53cz.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "输入是图片的像素值，20*20像素的图片有400个输入层单元，不包括需要额外添加的加上常数项。\n",
    "材料已经提供了训练好的神经网络的参数$\\Theta ^{(1)}$,$\\Theta^{(2)}$，有25个隐层单元和10个输出单元（10个输出）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69DEC958016646B7BA1D5E0B562C23A3",
    "mdEditEnable": false
   },
   "source": [
    "## 2.2 前馈神经网络和预测\n",
    "你需要实现前馈神经网络预测手写数字的功能。和之前的一对多分类一样，神经网络的预测会把$(h_\\theta(x))_k$中值最大的，作为预测输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4032B3F94D5940038F168C077F9BE13D",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 401), (10, 26))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = loadmat(\"/home/kesci/input/andrew_ml_ex33507/ex3weights.mat\")\n",
    "theta1, theta2 = weight['Theta1'], weight['Theta2']\n",
    "theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "E0C0419E7EF3432F91845B857AD1FFC1",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 插入常数项\n",
    "X2 = np.matrix(np.insert(data['X'], 0, values=np.ones(X.shape[0]), axis=1))\n",
    "y2 = np.matrix(data['y'])\n",
    "X2.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "330F06828E07400991665117B87EB449",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = X2\n",
    "z2 = a1 * theta1.T\n",
    "z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "E5CFFFCB1A2B489A8DD8FBEDC72FBFE8",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = sigmoid(z2)\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6DB786B8860048ACA19A4E473352FE79",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = np.insert(a2, 0, values=np.ones(a2.shape[0]), axis=1)\n",
    "z3 = a2 * theta2.T\n",
    "z3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "593CE389311742F385A01870C27EB83F",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.12661530e-04, 1.74127856e-03, 2.52696959e-03, ...,\n",
       "         4.01468105e-04, 6.48072305e-03, 9.95734012e-01],\n",
       "        [4.79026796e-04, 2.41495958e-03, 3.44755685e-03, ...,\n",
       "         2.39107046e-03, 1.97025086e-03, 9.95696931e-01],\n",
       "        [8.85702310e-05, 3.24266731e-03, 2.55419797e-02, ...,\n",
       "         6.22892325e-02, 5.49803551e-03, 9.28008397e-01],\n",
       "        ...,\n",
       "        [5.17641791e-02, 3.81715020e-03, 2.96297510e-02, ...,\n",
       "         2.15667361e-03, 6.49826950e-01, 2.42384687e-05],\n",
       "        [8.30631310e-04, 6.22003774e-04, 3.14518512e-04, ...,\n",
       "         1.19366192e-02, 9.71410499e-01, 2.06173648e-04],\n",
       "        [4.81465717e-05, 4.58821829e-04, 2.15146201e-05, ...,\n",
       "         5.73434571e-03, 6.96288990e-01, 8.18576980e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3 = sigmoid(z3)\n",
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9B669EAEF5F4497685D21C26BE8A1083",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = np.argmax(a3, axis=1) + 1\n",
    "y_pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BB640A124CAE4529974E4A09D141D239",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.99      0.97       500\n",
      "           2       0.95      0.92      0.93       500\n",
      "           3       0.95      0.91      0.93       500\n",
      "           4       0.95      0.95      0.95       500\n",
      "           5       0.92      0.92      0.92       500\n",
      "           6       0.97      0.98      0.97       500\n",
      "           7       0.95      0.95      0.95       500\n",
      "           8       0.93      0.92      0.92       500\n",
      "           9       0.92      0.92      0.92       500\n",
      "          10       0.97      0.99      0.98       500\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      5000\n",
      "   macro avg       0.94      0.94      0.94      5000\n",
      "weighted avg       0.94      0.94      0.94      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
